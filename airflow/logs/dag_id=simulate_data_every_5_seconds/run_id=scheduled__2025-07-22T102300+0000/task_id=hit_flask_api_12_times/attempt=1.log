[2025-07-22T10:24:50.705+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: simulate_data_every_5_seconds.hit_flask_api_12_times scheduled__2025-07-22T10:23:00+00:00 [queued]>
[2025-07-22T10:24:50.728+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: simulate_data_every_5_seconds.hit_flask_api_12_times scheduled__2025-07-22T10:23:00+00:00 [queued]>
[2025-07-22T10:24:50.729+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-07-22T10:24:50.763+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): hit_flask_api_12_times> on 2025-07-22 10:23:00+00:00
[2025-07-22T10:24:50.799+0000] {standard_task_runner.py:57} INFO - Started process 2552 to run task
[2025-07-22T10:24:50.894+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'simulate_data_every_5_seconds', 'hit_flask_api_12_times', 'scheduled__2025-07-22T10:23:00+00:00', '--job-id', '62', '--raw', '--subdir', 'DAGS_FOLDER/simulate_data_dag.py', '--cfg-path', '/tmp/tmpwnpkh0tf']
[2025-07-22T10:24:50.908+0000] {standard_task_runner.py:85} INFO - Job 62: Subtask hit_flask_api_12_times
[2025-07-22T10:24:52.360+0000] {task_command.py:416} INFO - Running <TaskInstance: simulate_data_every_5_seconds.hit_flask_api_12_times scheduled__2025-07-22T10:23:00+00:00 [running]> on host 539cb54e78a7
[2025-07-22T10:24:52.588+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='simulate_data_every_5_seconds' AIRFLOW_CTX_TASK_ID='hit_flask_api_12_times' AIRFLOW_CTX_EXECUTION_DATE='2025-07-22T10:23:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-07-22T10:23:00+00:00'
[2025-07-22T10:24:55.523+0000] {logging_mixin.py:154} INFO - Found working URL: http://host.docker.internal:5000
[2025-07-22T10:24:55.593+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 96, 'SPO2': 96, 'TEMP': 97.8, 'hadm_id': '3df9083769048a26f9dc22b01e05b712e7f738b670708de1d7bbde56a4875aef', 'masktype': 0, 'timestamp': '2025-07-22T15:54:55.561293'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:00.723+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 106, 'SPO2': 93, 'TEMP': 100.1, 'hadm_id': 'b6db6f8b80360e7d0ee316206b6ecf656bb5154ee74d2eee2a6ad78582b8dc12', 'masktype': 0, 'timestamp': '2025-07-22T15:55:00.703442'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:05.775+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 69, 'SPO2': 91, 'TEMP': 98.2, 'hadm_id': '815573775e968b26dbc289d9cee3faa6ffd200dd7ac7db90a023e5134b55e1ee', 'masktype': 0, 'timestamp': '2025-07-22T15:55:05.761883'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:10.871+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 63, 'SPO2': 92, 'TEMP': 98.3, 'hadm_id': '6686fc4c74906865248b0f2fcf5c246709215eda68cab15f8a70bb2e63f5bf7d', 'masktype': 1, 'timestamp': '2025-07-22T15:55:10.825035'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:16.048+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 113, 'SPO2': 92, 'TEMP': 100.7, 'hadm_id': '3e0cbdb59cf8a8edaf262fa5147f25e3bad06cd1eea3f6156aab3a96bf1e4be8', 'masktype': 1, 'timestamp': '2025-07-22T15:55:15.997330'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:21.338+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 102, 'SPO2': 90, 'TEMP': 99.2, 'hadm_id': '17674574828520aa5f240bbbdf40521549a514c0145e431f11e494d9923073c7', 'masktype': 0, 'timestamp': '2025-07-22T15:55:21.216190'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:36.580+0000] {logging_mixin.py:154} INFO - Error calling Flask API: HTTPConnectionPool(host='host.docker.internal', port=5000): Max retries exceeded with url: /send-vitals (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d4ed0159be0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))
[2025-07-22T10:25:43.573+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 111, 'SPO2': 99, 'TEMP': 101.2, 'hadm_id': 'b53a7292b38e011dbe6efc79c22d028ddd364da2e6b9aa182915572742330ea9', 'masktype': 1, 'timestamp': '2025-07-22T15:55:43.067280'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:48.764+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 118, 'SPO2': 91, 'TEMP': 100.5, 'hadm_id': 'f0eab88acf23e27842103370ed4fd13441881e47fe9e004ac4e52864978c55da', 'masktype': 1, 'timestamp': '2025-07-22T15:55:48.695281'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:53.844+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 118, 'SPO2': 90, 'TEMP': 98.3, 'hadm_id': '903a4207be29cb52c7c28b6b3e83b7bea776a390167924fe8ff18aa325f10285', 'masktype': 0, 'timestamp': '2025-07-22T15:55:53.828869'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:25:58.907+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 74, 'SPO2': 95, 'TEMP': 101.4, 'hadm_id': 'fe6340be87fd5e43b7f0cac5741e76205dd69a68b2024fda16c696848a720f7a', 'masktype': 0, 'timestamp': '2025-07-22T15:55:58.883766'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:26:04.035+0000] {logging_mixin.py:154} INFO - API response: {'data': {'HR': 113, 'SPO2': 91, 'TEMP': 102.4, 'hadm_id': 'bc1b62ebf83894d66c94159b2484ad8e8b1ab94c1cb2e5b9121afce752c73954', 'masktype': 1, 'timestamp': '2025-07-22T15:56:04.004212'}, 'message': 'Vitals sent', 'status': 'success'}
[2025-07-22T10:26:09.053+0000] {python.py:194} INFO - Done. Returned value was: None
[2025-07-22T10:26:09.587+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=simulate_data_every_5_seconds, task_id=hit_flask_api_12_times, execution_date=20250722T102300, start_date=20250722T102450, end_date=20250722T102609
[2025-07-22T10:26:10.125+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-07-22T10:26:10.598+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
